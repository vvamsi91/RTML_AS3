{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNvAnaYulisFMVQdK8Z52GF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvamsi91/RTML_AS3/blob/main/RTML_AS3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUOM4X8GNG4n",
        "outputId": "72769332-4ddb-41f3-aa71-a586f99f3d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 377 µs (started: 2024-03-09 03:31:22 +00:00)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score\n",
        "from tqdm.notebook import tqdm\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)\n",
        "np.random.seed(123)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OLdL5bQNvK9",
        "outputId": "bc462de7-50a7-464e-e192-5cc87781adc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.39 ms (started: 2024-03-09 03:31:45 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAKG_kJcN4AI",
        "outputId": "64a1bf2b-9996-4d2f-fcfe-60b250fb2984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 58.4 ms (started: 2024-03-09 03:31:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CharLSTM, self).__init__()\n",
        "\n",
        "        # Set hyperparameters\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embed input sequence\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Apply LSTM layer\n",
        "        output, _ = self.lstm(embedded)\n",
        "\n",
        "        # Extract the last time step and pass through the linear layer\n",
        "        output = self.fc(output[:, -1, :])\n",
        "\n",
        "        return output\n",
        "\n",
        "class CharGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CharGRU, self).__init__()\n",
        "\n",
        "        # Set hyperparameters\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embed input sequence\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Apply GRU layer\n",
        "        output, _ = self.gru(embedded)\n",
        "\n",
        "        # Extract the last time step and pass through the linear layer\n",
        "        output = self.fc(output[:, -1, :])\n",
        "\n",
        "        return output\n",
        "\n",
        "def predict_next_char(model, char_to_ix, ix_to_char, initial_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_ix (dict): Mapping from characters to indices.\n",
        "        ix_to_char (dict): Mapping from indices to characters.\n",
        "        initial_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        str: Predicted next character.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        initial_input = torch.tensor([char_to_ix[c] for c in initial_str[-max_length:]], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        prediction = model(initial_input)\n",
        "        predicted_index = torch.argmax(prediction, dim=1).item()\n",
        "        return ix_to_char[predicted_index]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVzVzKyROOiL",
        "outputId": "bba1ccf3-cb04-4b78-fb55-4219d05dd110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.2 ms (started: 2024-03-09 03:31:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "# Step 1: Download the dataset\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text  # This is the entire text data\n",
        "\n",
        "# Step 2: Prepare the dataset\n",
        "sequence_length = 20\n",
        "\n",
        "# Create a character mapping to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encode the text into integers\n",
        "encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "# Create sequences and targets\n",
        "sequences = [encoded_text[i:i + sequence_length] for i in range(0, len(encoded_text) - sequence_length)]\n",
        "targets = encoded_text[sequence_length:]\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Step 3: Create a dataset class\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.sequences[index], self.targets[index]\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CharDataset(sequences, targets)\n",
        "\n",
        "# Step 4: Create data loaders\n",
        "batch_size = 128\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE-56rl6Oetz",
        "outputId": "4c44125b-eb27-4bf8-a5a3-041a99d8d953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.99 s (started: 2024-03-09 03:32:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=20):\n",
        "    \"\"\"\n",
        "    Train and evaluate a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        criterion: Loss function.\n",
        "        optimizer: Optimizer for training.\n",
        "        train_loader (DataLoader): DataLoader for the training set.\n",
        "        test_loader (DataLoader): DataLoader for the test set.\n",
        "        device (str): Device for training and evaluation (default is 'cuda').\n",
        "        n_epochs (int): Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing training loss, validation loss, validation accuracy, and the trained model.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_list, val_loss_list, val_accuracy_list = [], [], []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss_list.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Validation loop\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss_list.append(running_loss / len(test_loader))\n",
        "            val_accuracy = 100 * (correct / total)\n",
        "            val_accuracy_list.append(val_accuracy)\n",
        "            print(f'Epoch {epoch + 1}, Training loss: {train_loss_list[-1]:.4f}, Validation loss: {val_loss_list[-1]:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    return {\n",
        "        'train_loss': train_loss_list,\n",
        "        'val_loss': val_loss_list,\n",
        "        'val_accuracy': val_accuracy_list,\n",
        "        'model': model\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCfva-tVO0-a",
        "outputId": "d18ad50f-78e1-43de-aba9-65ecefd7797f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.07 ms (started: 2024-03-09 03:32:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "hidden_size = 128\n",
        "learning_rate = 0.005\n",
        "epochs = 100\n",
        "\n",
        "# Instantiate the CharLSTM model\n",
        "model = CharLSTM(input_size=len(chars), hidden_size=hidden_size, output_size=len(chars))\n",
        "\n",
        "# Move the model to the specified device (e.g., 'cuda' or 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define the CrossEntropyLoss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the Adam optimizer for training\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMHX8cMtPFhQ",
        "outputId": "35a71af2-afff-4b7e-a7d7-e13cbf3645ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 579 ms (started: 2024-03-09 03:32:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_results = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7MpZs6qP4sN",
        "outputId": "7baa2af4-b512-442a-c6f4-b03cc6024ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.7496, Validation loss: 1.6346, Validation Accuracy: 50.72%\n",
            "Epoch 2, Training loss: 1.5917, Validation loss: 1.5862, Validation Accuracy: 52.09%\n",
            "Epoch 3, Training loss: 1.5592, Validation loss: 1.5802, Validation Accuracy: 52.10%\n",
            "Epoch 4, Training loss: 1.5470, Validation loss: 1.5604, Validation Accuracy: 52.83%\n",
            "Epoch 5, Training loss: 1.5388, Validation loss: 1.5624, Validation Accuracy: 52.59%\n",
            "Epoch 6, Training loss: 1.5363, Validation loss: 1.5551, Validation Accuracy: 53.10%\n",
            "Epoch 7, Training loss: 1.5365, Validation loss: 1.5626, Validation Accuracy: 52.71%\n",
            "Epoch 8, Training loss: 1.5390, Validation loss: 1.5642, Validation Accuracy: 52.52%\n",
            "Epoch 9, Training loss: 1.5413, Validation loss: 1.5635, Validation Accuracy: 52.59%\n",
            "Epoch 10, Training loss: 1.5400, Validation loss: 1.5631, Validation Accuracy: 52.66%\n",
            "time: 4min 13s (started: 2024-03-09 03:32:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the LSTM model\n",
        "total_params = get_total_parameters(lstm_results['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9eZjiv2RU3P",
        "outputId": "f557e5da-d8ed-4bd5-bde0-acd2a5c46ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 148801\n",
            "time: 969 µs (started: 2024-03-09 03:38:46 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the LSTM model\n",
        "predict_and_print_next_char(lstm_results['model'], char_to_int, int_to_char, test_str, max_length=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLXzX7xdTVuo",
        "outputId": "e514962e-c63e-4637-8c23-7f77b1029121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 3.23 ms (started: 2024-03-09 03:42:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Set hyperparameters\n",
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 80\n",
        "\n",
        "# Instantiate the CharGRU model\n",
        "model = CharGRU(input_size=len(chars), hidden_size=hidden_size, output_size=len(chars))\n",
        "\n",
        "# Move the model to the specified device (e.g., 'cuda' or 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define the CrossEntropyLoss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the Adam optimizer for training\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkNs64_sTipJ",
        "outputId": "7f5b8f55-b29c-4c53-f6e9-2cb7b588390a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.2 ms (started: 2024-03-09 03:44:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_results_20 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llACed3YUMyW",
        "outputId": "79e7fe84-c003-41e5-c2a2-83a4eaa8f692"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.6911, Validation loss: 1.5546, Validation Accuracy: 53.07%\n",
            "Epoch 2, Training loss: 1.5001, Validation loss: 1.4942, Validation Accuracy: 54.42%\n",
            "Epoch 3, Training loss: 1.4554, Validation loss: 1.4690, Validation Accuracy: 55.25%\n",
            "Epoch 4, Training loss: 1.4301, Validation loss: 1.4575, Validation Accuracy: 55.54%\n",
            "Epoch 5, Training loss: 1.4131, Validation loss: 1.4493, Validation Accuracy: 55.77%\n",
            "Epoch 6, Training loss: 1.4016, Validation loss: 1.4403, Validation Accuracy: 55.97%\n",
            "Epoch 7, Training loss: 1.3916, Validation loss: 1.4380, Validation Accuracy: 56.04%\n",
            "Epoch 8, Training loss: 1.3850, Validation loss: 1.4312, Validation Accuracy: 56.23%\n",
            "Epoch 9, Training loss: 1.3816, Validation loss: 1.4269, Validation Accuracy: 56.37%\n",
            "Epoch 10, Training loss: 1.3787, Validation loss: 1.4293, Validation Accuracy: 56.43%\n",
            "time: 5min 15s (started: 2024-03-09 03:45:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in gru_results_20['model'].parameters())\n",
        "print(f'Total number of parameters in the model: {total_params}')"
      ],
      "metadata": {
        "id": "9_4sLKVdUasa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddb5b41-6213-4aaa-eb71-86152a640d57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 428097\n",
            "time: 1.79 ms (started: 2024-03-09 03:51:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set sequence length\n",
        "sequence_length = 30\n",
        "\n",
        "# Create a character mapping to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encode the text into integers\n",
        "encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "# Create sequences and targets\n",
        "sequences = [encoded_text[i:i + sequence_length] for i in range(0, len(encoded_text) - sequence_length)]\n",
        "targets = encoded_text[sequence_length:]\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CharDataset(sequences, targets)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Use random_split for training and test datasets\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "vJDYko-iUfke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa54f52-438a-4de1-d7bf-9e48fdebe2a7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.09 s (started: 2024-03-09 03:54:52 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hidden_size = 128\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "model = CharLSTM(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdQVcWWXWC5g",
        "outputId": "51fed45f-2189-4810-9e4b-85718fd42551"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.56 ms (started: 2024-03-09 03:56:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_results_30 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1kbfKP_WtF6",
        "outputId": "c0f274e9-fd46-40d8-dfbe-77dbd42ff667"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.8294, Validation loss: 1.6304, Validation Accuracy: 51.47%\n",
            "Epoch 2, Training loss: 1.5760, Validation loss: 1.5420, Validation Accuracy: 53.60%\n",
            "Epoch 3, Training loss: 1.5094, Validation loss: 1.5014, Validation Accuracy: 54.75%\n",
            "Epoch 4, Training loss: 1.4723, Validation loss: 1.4778, Validation Accuracy: 55.15%\n",
            "Epoch 5, Training loss: 1.4475, Validation loss: 1.4593, Validation Accuracy: 55.66%\n",
            "Epoch 6, Training loss: 1.4295, Validation loss: 1.4495, Validation Accuracy: 55.95%\n",
            "Epoch 7, Training loss: 1.4158, Validation loss: 1.4375, Validation Accuracy: 56.31%\n",
            "Epoch 8, Training loss: 1.4040, Validation loss: 1.4262, Validation Accuracy: 56.50%\n",
            "Epoch 9, Training loss: 1.3937, Validation loss: 1.4251, Validation Accuracy: 56.67%\n",
            "Epoch 10, Training loss: 1.3853, Validation loss: 1.4212, Validation Accuracy: 56.66%\n",
            "time: 4min 48s (started: 2024-03-09 03:56:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the LSTM model with sequence length 30\n",
        "total_params = get_total_parameters(lstm_results_30['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE1HrW6iW1NR",
        "outputId": "3c6fd8c3-ba0c-4163-9526-7f1fa8cb897c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 148801\n",
            "time: 986 µs (started: 2024-03-09 04:02:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the LSTM model with sequence length 30\n",
        "predict_and_print_next_char(lstm_results_30['model'], char_to_int, int_to_char, test_str, max_length=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VilmztZzW_Lu",
        "outputId": "36ad5b1c-bbc0-471c-89f9-7b0b8579a396"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 3.63 ms (started: 2024-03-09 04:02:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "model = CharGRU(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKhwsQCVXqDh",
        "outputId": "49db0027-318a-45a5-af72-c4de95bb9bc9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.8 ms (started: 2024-03-09 04:02:09 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_results_30 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpE2Z2i2YBqE",
        "outputId": "598d62d5-b4f0-48b8-81ab-8cf0c8133b77"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.6879, Validation loss: 1.5394, Validation Accuracy: 53.49%\n",
            "Epoch 2, Training loss: 1.4951, Validation loss: 1.4787, Validation Accuracy: 54.77%\n",
            "Epoch 3, Training loss: 1.4479, Validation loss: 1.4545, Validation Accuracy: 55.83%\n",
            "Epoch 4, Training loss: 1.4222, Validation loss: 1.4342, Validation Accuracy: 56.23%\n",
            "Epoch 5, Training loss: 1.4057, Validation loss: 1.4257, Validation Accuracy: 56.64%\n",
            "Epoch 6, Training loss: 1.3939, Validation loss: 1.4263, Validation Accuracy: 56.54%\n",
            "Epoch 7, Training loss: 1.3851, Validation loss: 1.4193, Validation Accuracy: 56.76%\n",
            "Epoch 8, Training loss: 1.3777, Validation loss: 1.4155, Validation Accuracy: 56.93%\n",
            "Epoch 9, Training loss: 1.3733, Validation loss: 1.4076, Validation Accuracy: 56.94%\n",
            "Epoch 10, Training loss: 1.3682, Validation loss: 1.4132, Validation Accuracy: 57.01%\n",
            "time: 6min 57s (started: 2024-03-09 04:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the GRU model with sequence length 30\n",
        "total_params = get_total_parameters(gru_results_30['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JtwrrPnYFJ0",
        "outputId": "fa244651-fc2b-4794-d578-680664e1a8ba"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 428097\n",
            "time: 1.31 ms (started: 2024-03-09 04:09:35 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the GRU model with sequence length 30\n",
        "predict_and_print_next_char(gru_results_30['model'], char_to_int, int_to_char, test_str, max_length=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyvutioSYNzy",
        "outputId": "7a297784-2935-41c7-e07d-8475308afe97"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 3.73 ms (started: 2024-03-09 04:09:37 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = CharLSTM(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXdY7hSkYabN",
        "outputId": "dca02a84-1745-4858-e9d2-e703864912c2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 15.9 ms (started: 2024-03-09 04:10:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_results__hidden_20 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ve_-VcNYot6",
        "outputId": "b46d1b0f-69b9-4c85-e94c-942e7c1ffdf0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.7001, Validation loss: 1.5269, Validation Accuracy: 53.85%\n",
            "Epoch 2, Training loss: 1.4764, Validation loss: 1.4500, Validation Accuracy: 55.83%\n",
            "Epoch 3, Training loss: 1.4161, Validation loss: 1.4181, Validation Accuracy: 56.55%\n",
            "Epoch 4, Training loss: 1.3808, Validation loss: 1.3949, Validation Accuracy: 57.12%\n",
            "Epoch 5, Training loss: 1.3561, Validation loss: 1.3813, Validation Accuracy: 57.63%\n",
            "Epoch 6, Training loss: 1.3363, Validation loss: 1.3719, Validation Accuracy: 57.70%\n",
            "Epoch 7, Training loss: 1.3213, Validation loss: 1.3640, Validation Accuracy: 58.20%\n",
            "Epoch 8, Training loss: 1.3084, Validation loss: 1.3593, Validation Accuracy: 58.00%\n",
            "Epoch 9, Training loss: 1.2965, Validation loss: 1.3545, Validation Accuracy: 58.22%\n",
            "Epoch 10, Training loss: 1.2866, Validation loss: 1.3498, Validation Accuracy: 58.44%\n",
            "time: 7min 37s (started: 2024-03-09 04:10:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the LSTM model with hidden size 20\n",
        "total_params = get_total_parameters(lstm_results__hidden_20['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXzVsmWTZ247",
        "outputId": "2b0d26cd-c2f3-4fd5-c880-340222d2ec1a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 559681\n",
            "time: 970 µs (started: 2024-03-09 04:21:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the LSTM model with hidden size 20 and sequence length 30\n",
        "predict_and_print_next_char(lstm_results__hidden_20['model'], char_to_int, int_to_char, test_str, max_length=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-uWQ1L1aAkX",
        "outputId": "62124246-5177-4db1-f69f-ef5e52741cc9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 27.2 ms (started: 2024-03-09 04:22:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = CharGRU(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Vwi-0ZaegQ",
        "outputId": "01ff618b-e0d8-46f6-c065-5703c01a959b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.36 ms (started: 2024-03-09 04:22:17 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_results__hidden_20 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8XgksJAalS7",
        "outputId": "d519317f-439c-464f-fcdc-1684e48ad462"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.6885, Validation loss: 1.5468, Validation Accuracy: 53.36%\n",
            "Epoch 2, Training loss: 1.4936, Validation loss: 1.4820, Validation Accuracy: 54.93%\n",
            "Epoch 3, Training loss: 1.4460, Validation loss: 1.4532, Validation Accuracy: 55.77%\n",
            "Epoch 4, Training loss: 1.4220, Validation loss: 1.4418, Validation Accuracy: 55.84%\n",
            "Epoch 5, Training loss: 1.4050, Validation loss: 1.4285, Validation Accuracy: 56.45%\n",
            "Epoch 6, Training loss: 1.3918, Validation loss: 1.4198, Validation Accuracy: 56.62%\n",
            "Epoch 7, Training loss: 1.3833, Validation loss: 1.4166, Validation Accuracy: 57.05%\n",
            "Epoch 8, Training loss: 1.3766, Validation loss: 1.4094, Validation Accuracy: 57.16%\n",
            "Epoch 9, Training loss: 1.3717, Validation loss: 1.4137, Validation Accuracy: 56.91%\n",
            "Epoch 10, Training loss: 1.3690, Validation loss: 1.4117, Validation Accuracy: 56.87%\n",
            "time: 6min 50s (started: 2024-03-09 04:22:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the GRU model with hidden size 20 and sequence length 30\n",
        "predict_and_print_next_char(gru_results__hidden_20['model'], char_to_int, int_to_char, test_str, max_length=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWRIYAyTbH6f",
        "outputId": "9dc4a691-7b0b-4eb0-afd5-ec3aaba86edc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 4.51 ms (started: 2024-03-09 04:33:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the GRU model with hidden size 20 and sequence length 30\n",
        "predict_and_print_next_char(gru_results__hidden_20['model'], char_to_int, int_to_char, test_str, max_length=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDvHHBZic23s",
        "outputId": "ac155d2b-f555-4fa2-c4f7-15ab7c5e84c4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 3.37 ms (started: 2024-03-09 04:33:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the character mapping to integers\n",
        "char_to_int = {ch: i for i, ch in enumerate(sorted(set(text)))}\n",
        "int_to_char = {i: ch for i, ch in enumerate(sorted(set(text)))}\n",
        "\n",
        "# Encode the text into integers\n",
        "encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "# Create sequences and targets\n",
        "sequences = [encoded_text[i:i + sequence_length] for i in range(len(encoded_text) - sequence_length)]\n",
        "targets = encoded_text[sequence_length:]\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CharDataset(sequences, targets)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdlrSt0FdNR_",
        "outputId": "b6dee941-ee27-4da7-fe76-59cff26231a7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.5 s (started: 2024-03-09 04:33:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = CharLSTM(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjDqJmKtfN-N",
        "outputId": "2070cfb4-cd1d-4a27-a13b-1391009e847a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.2 ms (started: 2024-03-09 04:34:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_results__hidden_30 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGylFdfHfXY8",
        "outputId": "202b736d-919b-4190-8ed8-800c38cd2d32"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.6992, Validation loss: 1.5287, Validation Accuracy: 53.86%\n",
            "Epoch 2, Training loss: 1.4756, Validation loss: 1.4589, Validation Accuracy: 55.45%\n",
            "Epoch 3, Training loss: 1.4139, Validation loss: 1.4218, Validation Accuracy: 56.47%\n",
            "Epoch 4, Training loss: 1.3778, Validation loss: 1.4024, Validation Accuracy: 57.05%\n",
            "Epoch 5, Training loss: 1.3521, Validation loss: 1.3862, Validation Accuracy: 57.38%\n",
            "Epoch 6, Training loss: 1.3324, Validation loss: 1.3759, Validation Accuracy: 57.74%\n",
            "Epoch 7, Training loss: 1.3165, Validation loss: 1.3724, Validation Accuracy: 57.75%\n",
            "Epoch 8, Training loss: 1.3037, Validation loss: 1.3685, Validation Accuracy: 57.95%\n",
            "Epoch 9, Training loss: 1.2932, Validation loss: 1.3591, Validation Accuracy: 58.25%\n",
            "Epoch 10, Training loss: 1.2833, Validation loss: 1.3538, Validation Accuracy: 58.46%\n",
            "time: 7min 35s (started: 2024-03-09 04:34:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the LSTM model with hidden size 30\n",
        "total_params = calculate_total_parameters(lstm_results__hidden_30['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9jzkTn8fdtt",
        "outputId": "1e0ea811-00b5-458d-ffab-88e801654605"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 559681\n",
            "time: 2.28 ms (started: 2024-03-09 04:42:50 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the LSTM model with hidden size 30 and sequence length 30\n",
        "predict_and_print_next_char(lstm_results__hidden_30['model'], char_to_int, int_to_char, test_str, max_length=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56eV0W9RfrUq",
        "outputId": "31cb94b9-a188-4f39-bbb0-860608df659a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 4.39 ms (started: 2024-03-09 04:43:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = CharGRU(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leu_3VIYhZfH",
        "outputId": "77ee6561-c53a-46ac-90dc-2b32178351c7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 9.98 ms (started: 2024-03-09 04:43:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_results_hidden_30 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmXgnE50hkDy",
        "outputId": "8caeccf9-9312-45da-89f1-2b2e4e36bf59"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.6907, Validation loss: 1.5413, Validation Accuracy: 53.36%\n",
            "Epoch 2, Training loss: 1.4937, Validation loss: 1.4820, Validation Accuracy: 54.83%\n",
            "Epoch 3, Training loss: 1.4465, Validation loss: 1.4581, Validation Accuracy: 55.58%\n",
            "Epoch 4, Training loss: 1.4209, Validation loss: 1.4466, Validation Accuracy: 56.13%\n",
            "Epoch 5, Training loss: 1.4029, Validation loss: 1.4328, Validation Accuracy: 56.29%\n",
            "Epoch 6, Training loss: 1.3913, Validation loss: 1.4292, Validation Accuracy: 56.47%\n",
            "Epoch 7, Training loss: 1.3837, Validation loss: 1.4245, Validation Accuracy: 56.63%\n",
            "Epoch 8, Training loss: 1.3758, Validation loss: 1.4232, Validation Accuracy: 56.42%\n",
            "Epoch 9, Training loss: 1.3707, Validation loss: 1.4211, Validation Accuracy: 56.57%\n",
            "Epoch 10, Training loss: 1.3690, Validation loss: 1.4189, Validation Accuracy: 56.97%\n",
            "time: 6min 56s (started: 2024-03-09 04:43:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the GRU model with hidden size 30\n",
        "total_params = calculate_total_parameters(gru_results_hidden_30['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUq4q-Gvhm-e",
        "outputId": "15fcdac2-63b7-46b3-801f-e76f385d2bda"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 428097\n",
            "time: 2.46 ms (started: 2024-03-09 04:51:37 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_print_next_char(model, char_to_int, int_to_char, test_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict and print the next character in a sequence using the trained model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_int (dict): Mapping from characters to indices.\n",
        "        int_to_char (dict): Mapping from indices to characters.\n",
        "        test_str (str): The initial sequence.\n",
        "        max_length (int): Maximum length of the sequence used for prediction.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    predicted_char = predict_next_char(model, char_to_int, int_to_char, test_str, max_length)\n",
        "    print(f\"Predicted next character: '{predicted_char}'\")\n",
        "\n",
        "# Predict and print the next character for the GRU model with hidden size 30 and sequence length 30\n",
        "predict_and_print_next_char(gru_results_hidden_30['model'], char_to_int, int_to_char, test_str, max_length=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg7K-VMXh5Vq",
        "outputId": "01432628-2c5a-4c86-ad71-2212e9c207a3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 4.21 ms (started: 2024-03-09 04:51:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a character mapping to integers\n",
        "def create_char_mappings(text):\n",
        "    chars = sorted(list(set(text)))\n",
        "    char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "    int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "    return char_to_int, int_to_char\n",
        "\n",
        "# Function to encode text into integers and create sequences with targets\n",
        "def encode_and_create_sequences(text, sequence_length, char_to_int):\n",
        "    encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(0, len(encoded_text) - sequence_length):\n",
        "        seq = encoded_text[i:i+sequence_length]\n",
        "        target = encoded_text[i+sequence_length]\n",
        "        sequences.append(seq)\n",
        "        targets.append(target)\n",
        "\n",
        "    sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "    targets = torch.tensor(targets, dtype=torch.long)\n",
        "    return sequences, targets\n",
        "\n",
        "# Create character mappings\n",
        "char_to_int, int_to_char = create_char_mappings(text)\n",
        "\n",
        "# Encode text into integers and create sequences with targets\n",
        "sequences, targets = encode_and_create_sequences(text, sequence_length, char_to_int)\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CharDataset(sequences, targets)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8e_jWRbjXoy",
        "outputId": "36736925-4d84-49ed-8225-f4b2765239bc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.11 s (started: 2024-03-09 04:52:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = CharLSTM(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R0Nmn4zjmjp",
        "outputId": "5306aa86-3021-4b71-d0e2-00f1346c4d01"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.5 ms (started: 2024-03-09 04:53:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_results_hidden_50 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz0Nf2aijt1m",
        "outputId": "868ac87e-6b45-467d-86cd-497e019fdea2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.6984, Validation loss: 1.5297, Validation Accuracy: 53.61%\n",
            "Epoch 2, Training loss: 1.4732, Validation loss: 1.4506, Validation Accuracy: 55.56%\n",
            "Epoch 3, Training loss: 1.4118, Validation loss: 1.4172, Validation Accuracy: 56.72%\n",
            "Epoch 4, Training loss: 1.3776, Validation loss: 1.3917, Validation Accuracy: 57.41%\n",
            "Epoch 5, Training loss: 1.3520, Validation loss: 1.3810, Validation Accuracy: 57.52%\n",
            "Epoch 6, Training loss: 1.3322, Validation loss: 1.3740, Validation Accuracy: 57.82%\n",
            "Epoch 7, Training loss: 1.3168, Validation loss: 1.3641, Validation Accuracy: 58.09%\n",
            "Epoch 8, Training loss: 1.3043, Validation loss: 1.3614, Validation Accuracy: 58.25%\n",
            "Epoch 9, Training loss: 1.2927, Validation loss: 1.3619, Validation Accuracy: 58.19%\n",
            "Epoch 10, Training loss: 1.2838, Validation loss: 1.3530, Validation Accuracy: 58.66%\n",
            "time: 7min 35s (started: 2024-03-09 04:53:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the LSTM model with hidden size 50\n",
        "total_params = calculate_total_parameters(lstm_results_hidden_50['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDZ95wXFjyff",
        "outputId": "24ebfa7b-7cd5-4e97-a7eb-fc0f8690f617"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 559681\n",
            "time: 2.06 ms (started: 2024-03-09 05:02:23 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = CharGRU(len(chars), hidden_size, len(chars))\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3q8Lz37kAgm",
        "outputId": "5670e738-f8e6-4e68-8b55-571bb7648614"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.4 ms (started: 2024-03-09 05:04:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_results_hidden_50 = train_and_evaluate_model(model, criterion, optimizer, train_loader, test_loader, device='cuda', n_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uNAy_2tmPOO",
        "outputId": "0d54889c-dbd6-4292-cd46-bd8a4f86c3e7"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss: 1.6843, Validation loss: 1.5365, Validation Accuracy: 53.77%\n",
            "Epoch 2, Training loss: 1.4914, Validation loss: 1.4855, Validation Accuracy: 54.88%\n",
            "Epoch 3, Training loss: 1.4452, Validation loss: 1.4534, Validation Accuracy: 55.83%\n",
            "Epoch 4, Training loss: 1.4199, Validation loss: 1.4355, Validation Accuracy: 56.29%\n",
            "Epoch 5, Training loss: 1.4026, Validation loss: 1.4350, Validation Accuracy: 56.29%\n",
            "Epoch 6, Training loss: 1.3907, Validation loss: 1.4254, Validation Accuracy: 56.41%\n",
            "Epoch 7, Training loss: 1.3833, Validation loss: 1.4276, Validation Accuracy: 56.21%\n",
            "Epoch 8, Training loss: 1.3763, Validation loss: 1.4181, Validation Accuracy: 56.77%\n",
            "Epoch 9, Training loss: 1.3723, Validation loss: 1.4145, Validation Accuracy: 56.74%\n",
            "Epoch 10, Training loss: 1.3672, Validation loss: 1.4126, Validation Accuracy: 56.87%\n",
            "time: 6min 50s (started: 2024-03-09 05:04:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_total_parameters(model):\n",
        "    \"\"\"\n",
        "    Calculate the total number of parameters in a PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Get total parameters for the GRU model with hidden size 50\n",
        "total_params = calculate_total_parameters(gru_results_hidden_50['model'])\n",
        "print(f'Total number of parameters in the model: {total_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GUJbgzgmR51",
        "outputId": "3be5dcd9-fa35-4f57-b04a-13765a900c6a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 428097\n",
            "time: 2.44 ms (started: 2024-03-09 05:12:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_character(model, char_to_ix, ix_to_char, initial_str, max_length):\n",
        "    \"\"\"\n",
        "    Predict the next character using a trained PyTorch model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model.\n",
        "        char_to_ix (dict): Mapping from characters to integers.\n",
        "        ix_to_char (dict): Mapping from integers to characters.\n",
        "        initial_str (str): Initial string for prediction.\n",
        "        max_length (int): Maximum length of the sequence.\n",
        "\n",
        "    Returns:\n",
        "        str: Predicted next character.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        initial_input = torch.tensor([char_to_ix[c] for c in initial_str[-max_length:]], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        prediction = model(initial_input)\n",
        "        predicted_index = torch.argmax(prediction, dim=1).item()\n",
        "        return ix_to_char[predicted_index]\n",
        "\n",
        "# Test the prediction for the GRU model with hidden size 50\n",
        "predicted_char = predict_next_character(gru_results_hidden_50['model'], char_to_int, int_to_char, test_str, 30)\n",
        "print(f\"Predicted next character: '{predicted_char}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey9yYuh4mba4",
        "outputId": "d12500c3-707f-46ae-fdc2-a756345b7661"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next character: 'g'\n",
            "time: 4.56 ms (started: 2024-03-09 05:12:06 +00:00)\n"
          ]
        }
      ]
    }
  ]
}